{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[{"file_id":"1zp5U9mElFIw-LW1kGdhARzopOyLEGBf4","timestamp":1683302267212},{"file_id":"1RcH27JixN1ONhTqNbIsoVugNJEaM2HvA","timestamp":1589307633782}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"UPy8O0DVLIl9"},"source":["# CSC-321: Data Mining and Machine Learning\n","# Manav Bilakhia\n","## Assignment 7: K-Nearest Neighbor\n","\n","### Part 1: Implementation\n","\n","For this assignment, I'm going to let you break down the implementation as you see fit. You're going to implement KNN, an example of lazy learning. In brief, this means:\n","\n","- calculating euclidean distance between the feature values of a single test instance, and the feature values of a single training instance\n","- making a prediction requires iterating through *all* the training instances, calculating the distances and storing each distance in a list, along with the corresponding class value (probably as some sort of tuple)\n","- sorting the list, smallest distances first\n","- selecting the *k* nearest neighbors (where k should be a parameter)\n","- making a prediction by choosing the class that appears the most in the k nearest neighbors\n","\n","To calculate euclidean distance between an instance x1 and an instance x2, we need to iterate through the input features of the two instances (for i features) and for each take the difference of (x1[i]) - (x2[i]), squaring that difference, and summing over all features. At the end, take the square root of the total. In other words:\n","\n","$$distance=\\sqrt{\\sum_{i=1}^n (x1_{i} - x2_{i})^2}$$\n","\n","\n","I would strongly suggest you follow the implementation outline of previous algorithms in terms of the functions you use, but I'm leaving it up to you.\n","\n","Below is the same contrived dataset you've used before. If your code works, you should be able to take an instance of this data, and compare it to all the others (including itself, where the distance SHOULD be 0). You should be able to select the k-nearest neighbors, and make a prediction based on the most frequently occuring class in those k neighbors. Try it for different values of k, from 1, 3 and 5.\n","\n","Make sure you create a knn function that takes a training set (X_train, y_train), a test set (X_test) and a value for k, that returns a list of predictions - one prediction for each instance in the test set.\n","\n","Run the algorithm over the sample dataset, using k=3. Print the predicted and the actual side by side."]},{"cell_type":"code","metadata":{"id":"Pd25OACkLIl-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683506617297,"user_tz":240,"elapsed":4,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"78da455d-057a-4fed-99b1-1b619398d90b"},"source":["from collections import Counter\n","import math\n","\n","def euclidean_distance(x1, x2):\n","    distance = 0\n","    for i in range(len(x1)):\n","        distance += (x1[i] - x2[i]) ** 2\n","    return math.sqrt(distance)\n","\n","def knn(X_train, y_train, X_test, k):\n","    predictions = []\n","    for test_instance in X_test:\n","        distances = []\n","        for i, train_instance in enumerate(X_train):\n","            distance = euclidean_distance(train_instance, test_instance)\n","            distances.append((distance, y_train[i]))\n","        distances.sort()\n","        neighbors = [distances[i][1] for i in range(k)]\n","        most_common = Counter(neighbors).most_common(1)\n","        predictions.append(most_common[0][0])\n","    return predictions\n","\n","\n","# Contrived data set\n","dataset = [[3.393533211,2.331273381,0],\n","    [3.110073483,1.781539638,0],\n","    [1.343808831,3.368360954,0],\n","    [3.582294042,4.67917911,0],\n","    [2.280362439,2.866990263,0],\n","    [7.423436942,4.696522875,1],\n","    [5.745051997,3.533989803,1],\n","    [9.172168622,2.511101045,1],\n","    [7.792783481,3.424088941,1],\n","    [7.939820817,0.791637231,1]]\n","\n","X_train = [row[:-1] for row in dataset]\n","y_train = [row[-1] for row in dataset]\n","X_test = [[3.393533211,2.331273381],\n","    [7.423436942,4.696522875],\n","    [9.172168622,2.511101045]]\n","\n","k = 3\n","predictions = knn(X_train, y_train, X_test, k)\n","\n","# print predictions and actual values side by side\n","for i, prediction in enumerate(predictions):\n","    print(X_test[i], prediction)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3.393533211, 2.331273381] 0\n","[7.423436942, 4.696522875] 1\n","[9.172168622, 2.511101045] 1\n"]}]},{"cell_type":"markdown","metadata":{"id":"DwpFG6iQLImD"},"source":["### Part 2: Working with real data\n","\n","Apply the KNN algorithm above to the abalone data set. You can find more about it here: http://archive.ics.uci.edu/ml/datasets/Abalone\n","\n","I've started the process, because I want to show you another part of scikit learn. I've loaded in the data, and shown the head of the data. Pay attention to the sex column.\n"]},{"cell_type":"code","metadata":{"id":"bQYMk3UeLImE","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683506618681,"user_tz":240,"elapsed":1386,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"8f4cf68e-0a54-4324-e1e3-a6cc094c0213"},"source":["import pandas as pd\n","\n","labels = ['sex','length','diameter','height','whole_weight','shucked_weight',\n","          'viscera_weight','shell_weight','rings']\n","\n","abalone_data = pd.read_csv('https://raw.githubusercontent.com/nixwebb/CSV_Data/master/abalone.csv',names=labels)\n","abalone_data.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n","0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n","1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n","2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n","3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n","4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n","\n","   shell_weight  rings  \n","0         0.150     15  \n","1         0.070      7  \n","2         0.210      9  \n","3         0.155     10  \n","4         0.055      7  "],"text/html":["\n","  <div id=\"df-4fea565a-1491-446f-9ab7-ac18468469b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex</th>\n","      <th>length</th>\n","      <th>diameter</th>\n","      <th>height</th>\n","      <th>whole_weight</th>\n","      <th>shucked_weight</th>\n","      <th>viscera_weight</th>\n","      <th>shell_weight</th>\n","      <th>rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M</td>\n","      <td>0.455</td>\n","      <td>0.365</td>\n","      <td>0.095</td>\n","      <td>0.5140</td>\n","      <td>0.2245</td>\n","      <td>0.1010</td>\n","      <td>0.150</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M</td>\n","      <td>0.350</td>\n","      <td>0.265</td>\n","      <td>0.090</td>\n","      <td>0.2255</td>\n","      <td>0.0995</td>\n","      <td>0.0485</td>\n","      <td>0.070</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>F</td>\n","      <td>0.530</td>\n","      <td>0.420</td>\n","      <td>0.135</td>\n","      <td>0.6770</td>\n","      <td>0.2565</td>\n","      <td>0.1415</td>\n","      <td>0.210</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>0.440</td>\n","      <td>0.365</td>\n","      <td>0.125</td>\n","      <td>0.5160</td>\n","      <td>0.2155</td>\n","      <td>0.1140</td>\n","      <td>0.155</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I</td>\n","      <td>0.330</td>\n","      <td>0.255</td>\n","      <td>0.080</td>\n","      <td>0.2050</td>\n","      <td>0.0895</td>\n","      <td>0.0395</td>\n","      <td>0.055</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fea565a-1491-446f-9ab7-ac18468469b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fea565a-1491-446f-9ab7-ac18468469b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fea565a-1491-446f-9ab7-ac18468469b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"x63WpqWFytr5"},"source":["That first column is nominal data, not numeric. We first have to change it into numbers - either replacing each value with an integer (label encoding) or creating new columns to represent each possible value (one-hot encoding).\n","\n","For label encoding, I use the method in scikit learn. For one-hot encoding, if my data is in a pandas dataframe, I prefer the pandas method. Ultimately it doesn't matter, and you should feel free to check out both.\n","\n","Ultimately, I'll do one-hot encoding here. The method in pandas is called get_dummies. I'm going to do that in stages, to show you what happens, but you don't need to print after ever step like this, once you're convinced it works.\n","\n","The get_dummies method in pandas creates my new columns based on feature values. There are three possible feature values for the sex feature (M,F,I - and you should know what these mean), so I create three columns.\n","\n","Notice that in pandas I can refer to a column using a built in attribute. The abalone_data dataframe has a column labeled 'sex', so I can use abalone_data.sex to access that column. I'm creating column headings from the feature values, and adding the prefix 'sex' to each value."]},{"cell_type":"code","metadata":{"id":"021lQBjryuDr","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683506618682,"user_tz":240,"elapsed":6,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"91841028-d89e-4c29-85a2-569c493cdd79"},"source":["abalone_sex = pd.get_dummies(abalone_data.sex, prefix='sex')\n","abalone_sex.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sex_F  sex_I  sex_M\n","0      0      0      1\n","1      0      0      1\n","2      1      0      0\n","3      0      0      1\n","4      0      1      0"],"text/html":["\n","  <div id=\"df-062de257-72a2-40c8-8930-bda1adfb3410\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex_F</th>\n","      <th>sex_I</th>\n","      <th>sex_M</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-062de257-72a2-40c8-8930-bda1adfb3410')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-062de257-72a2-40c8-8930-bda1adfb3410 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-062de257-72a2-40c8-8930-bda1adfb3410');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"s8VcOB8Rz53N"},"source":["Then I need to add these columns back into my overall dataframe. I'm using the pandas method concat to do that."]},{"cell_type":"code","metadata":{"id":"M_SFobpgz4-Y","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683506618682,"user_tz":240,"elapsed":4,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"b6823dd0-d7bf-48c9-eece-b18227d28e1e"},"source":["abalone_ohe = pd.concat([abalone_sex,abalone_data],axis=1)\n","abalone_ohe.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sex_F  sex_I  sex_M sex  length  diameter  height  whole_weight  \\\n","0      0      0      1   M   0.455     0.365   0.095        0.5140   \n","1      0      0      1   M   0.350     0.265   0.090        0.2255   \n","2      1      0      0   F   0.530     0.420   0.135        0.6770   \n","3      0      0      1   M   0.440     0.365   0.125        0.5160   \n","4      0      1      0   I   0.330     0.255   0.080        0.2050   \n","\n","   shucked_weight  viscera_weight  shell_weight  rings  \n","0          0.2245          0.1010         0.150     15  \n","1          0.0995          0.0485         0.070      7  \n","2          0.2565          0.1415         0.210      9  \n","3          0.2155          0.1140         0.155     10  \n","4          0.0895          0.0395         0.055      7  "],"text/html":["\n","  <div id=\"df-4784b296-668b-48dd-92de-a97e7a660417\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex_F</th>\n","      <th>sex_I</th>\n","      <th>sex_M</th>\n","      <th>sex</th>\n","      <th>length</th>\n","      <th>diameter</th>\n","      <th>height</th>\n","      <th>whole_weight</th>\n","      <th>shucked_weight</th>\n","      <th>viscera_weight</th>\n","      <th>shell_weight</th>\n","      <th>rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>0.455</td>\n","      <td>0.365</td>\n","      <td>0.095</td>\n","      <td>0.5140</td>\n","      <td>0.2245</td>\n","      <td>0.1010</td>\n","      <td>0.150</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>0.350</td>\n","      <td>0.265</td>\n","      <td>0.090</td>\n","      <td>0.2255</td>\n","      <td>0.0995</td>\n","      <td>0.0485</td>\n","      <td>0.070</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>F</td>\n","      <td>0.530</td>\n","      <td>0.420</td>\n","      <td>0.135</td>\n","      <td>0.6770</td>\n","      <td>0.2565</td>\n","      <td>0.1415</td>\n","      <td>0.210</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>0.440</td>\n","      <td>0.365</td>\n","      <td>0.125</td>\n","      <td>0.5160</td>\n","      <td>0.2155</td>\n","      <td>0.1140</td>\n","      <td>0.155</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>I</td>\n","      <td>0.330</td>\n","      <td>0.255</td>\n","      <td>0.080</td>\n","      <td>0.2050</td>\n","      <td>0.0895</td>\n","      <td>0.0395</td>\n","      <td>0.055</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4784b296-668b-48dd-92de-a97e7a660417')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4784b296-668b-48dd-92de-a97e7a660417 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4784b296-668b-48dd-92de-a97e7a660417');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"O5o2eidcz4wh"},"source":["And finally, now I've encoded the sex using one-hot encoding, I'm going to drop the sex column from the dataframe. However, just to show you how the scikit learn label encoder works, execute the code in the first code cell below, and check out what happens to the sex column values. Then run the second cell to drop the sex column from the data."]},{"cell_type":"code","metadata":{"id":"MA3vKbHS6P4w","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683506620292,"user_tz":240,"elapsed":1614,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"7ff44909-42d6-4f8e-8412-9e205bd4dcd9"},"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","abalone_ohe['sex'] = le.fit_transform(abalone_ohe.sex.values)\n","abalone_ohe.head()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sex_F  sex_I  sex_M  sex  length  diameter  height  whole_weight  \\\n","0      0      0      1    2   0.455     0.365   0.095        0.5140   \n","1      0      0      1    2   0.350     0.265   0.090        0.2255   \n","2      1      0      0    0   0.530     0.420   0.135        0.6770   \n","3      0      0      1    2   0.440     0.365   0.125        0.5160   \n","4      0      1      0    1   0.330     0.255   0.080        0.2050   \n","\n","   shucked_weight  viscera_weight  shell_weight  rings  \n","0          0.2245          0.1010         0.150     15  \n","1          0.0995          0.0485         0.070      7  \n","2          0.2565          0.1415         0.210      9  \n","3          0.2155          0.1140         0.155     10  \n","4          0.0895          0.0395         0.055      7  "],"text/html":["\n","  <div id=\"df-f6bb2a96-d925-4085-a05e-38b452cfc1d3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex_F</th>\n","      <th>sex_I</th>\n","      <th>sex_M</th>\n","      <th>sex</th>\n","      <th>length</th>\n","      <th>diameter</th>\n","      <th>height</th>\n","      <th>whole_weight</th>\n","      <th>shucked_weight</th>\n","      <th>viscera_weight</th>\n","      <th>shell_weight</th>\n","      <th>rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.455</td>\n","      <td>0.365</td>\n","      <td>0.095</td>\n","      <td>0.5140</td>\n","      <td>0.2245</td>\n","      <td>0.1010</td>\n","      <td>0.150</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.350</td>\n","      <td>0.265</td>\n","      <td>0.090</td>\n","      <td>0.2255</td>\n","      <td>0.0995</td>\n","      <td>0.0485</td>\n","      <td>0.070</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.530</td>\n","      <td>0.420</td>\n","      <td>0.135</td>\n","      <td>0.6770</td>\n","      <td>0.2565</td>\n","      <td>0.1415</td>\n","      <td>0.210</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.440</td>\n","      <td>0.365</td>\n","      <td>0.125</td>\n","      <td>0.5160</td>\n","      <td>0.2155</td>\n","      <td>0.1140</td>\n","      <td>0.155</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.330</td>\n","      <td>0.255</td>\n","      <td>0.080</td>\n","      <td>0.2050</td>\n","      <td>0.0895</td>\n","      <td>0.0395</td>\n","      <td>0.055</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6bb2a96-d925-4085-a05e-38b452cfc1d3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6bb2a96-d925-4085-a05e-38b452cfc1d3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6bb2a96-d925-4085-a05e-38b452cfc1d3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"SXf6FhF2z4XG","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683506620293,"user_tz":240,"elapsed":5,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"7d1917c7-467e-41d6-aa86-c198272ac6ee"},"source":["abalone_ohe.drop('sex',axis=1,inplace=True)\n","abalone_ohe.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sex_F  sex_I  sex_M  length  diameter  height  whole_weight  \\\n","0      0      0      1   0.455     0.365   0.095        0.5140   \n","1      0      0      1   0.350     0.265   0.090        0.2255   \n","2      1      0      0   0.530     0.420   0.135        0.6770   \n","3      0      0      1   0.440     0.365   0.125        0.5160   \n","4      0      1      0   0.330     0.255   0.080        0.2050   \n","\n","   shucked_weight  viscera_weight  shell_weight  rings  \n","0          0.2245          0.1010         0.150     15  \n","1          0.0995          0.0485         0.070      7  \n","2          0.2565          0.1415         0.210      9  \n","3          0.2155          0.1140         0.155     10  \n","4          0.0895          0.0395         0.055      7  "],"text/html":["\n","  <div id=\"df-f8880af5-c521-44ee-9aa5-dfddf421cc19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex_F</th>\n","      <th>sex_I</th>\n","      <th>sex_M</th>\n","      <th>length</th>\n","      <th>diameter</th>\n","      <th>height</th>\n","      <th>whole_weight</th>\n","      <th>shucked_weight</th>\n","      <th>viscera_weight</th>\n","      <th>shell_weight</th>\n","      <th>rings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.455</td>\n","      <td>0.365</td>\n","      <td>0.095</td>\n","      <td>0.5140</td>\n","      <td>0.2245</td>\n","      <td>0.1010</td>\n","      <td>0.150</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.350</td>\n","      <td>0.265</td>\n","      <td>0.090</td>\n","      <td>0.2255</td>\n","      <td>0.0995</td>\n","      <td>0.0485</td>\n","      <td>0.070</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.530</td>\n","      <td>0.420</td>\n","      <td>0.135</td>\n","      <td>0.6770</td>\n","      <td>0.2565</td>\n","      <td>0.1415</td>\n","      <td>0.210</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.440</td>\n","      <td>0.365</td>\n","      <td>0.125</td>\n","      <td>0.5160</td>\n","      <td>0.2155</td>\n","      <td>0.1140</td>\n","      <td>0.155</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.330</td>\n","      <td>0.255</td>\n","      <td>0.080</td>\n","      <td>0.2050</td>\n","      <td>0.0895</td>\n","      <td>0.0395</td>\n","      <td>0.055</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8880af5-c521-44ee-9aa5-dfddf421cc19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f8880af5-c521-44ee-9aa5-dfddf421cc19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f8880af5-c521-44ee-9aa5-dfddf421cc19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"3Hc14fC3y5uz"},"source":["The y value for this data, the thing we're predicting, is the category represented by the number of rings.\n","\n","Using this dataset, extract X and y data, normalize the X values, and run a 5-fold cross-validation, with k set as 5. Also run a classification baseline. Report on classification accuracy, and write up some results.\n","\n","NOTE: This will be SLOW. If you're not sure your code is working, I recommend starting with a 3 fold cross-validation, and use k=1. You will probably get some UserWarnings from python also. I will explain these in class later."]},{"cell_type":"code","metadata":{"id":"Fc3HDWovy6o8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683506621082,"user_tz":240,"elapsed":793,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"7a6391af-a1f3-49a5-873c-82a332d39b99"},"source":["from sklearn.model_selection import KFold\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","# Extract X and y data\n","X = abalone_ohe.drop('rings', axis=1)\n","y = abalone_ohe['rings']\n","\n","# Normalize X data\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Define the KNN model\n","knn = KNeighborsClassifier(n_neighbors=5)\n","\n","# Run a 5-fold cross-validation\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","accuracy_scores = []\n","for train_index, test_index in kf.split(X):\n","    # Split the data into train and test sets\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # Train the model on the train set and predict on the test set\n","    knn.fit(X_train, y_train)\n","    y_pred = knn.predict(X_test)\n","\n","    # Calculate the accuracy score and append to the list\n","    accuracy_scores.append(accuracy_score(y_test, y_pred))\n","\n","# Report the results\n","print('Classification accuracy:', sum(accuracy_scores)/len(accuracy_scores))\n","\n","\n","from collections import Counter\n","\n","# Calculate the majority class\n","majority_class = Counter(y).most_common(1)[0][0]\n","\n","# Predict the majority class for all instances\n","baseline_preds = [majority_class] * len(y)\n","\n","# Calculate the accuracy score for the baseline\n","baseline_acc = accuracy_score(y, baseline_preds)\n","\n","print('Baseline accuracy:', baseline_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification accuracy: 0.22431768042861644\n","Baseline accuracy: 0.1649509217141489\n"]}]},{"cell_type":"markdown","metadata":{"id":"RUQ6PGtZLImI"},"source":["Running this code, we get a baseline accuracy of 16.49%, which means that if we always predict the most common number of rings (9), we would be correct 18.97% of the time.\n","\n","Comparing the KNN accuracy to the baseline accuracy, we can see that the KNN algorithm is much more accurate. However, we can still try to improve the accuracy by tuning the hyperparameters of the KNN model or trying different algorithms.\n"]},{"cell_type":"markdown","metadata":{"id":"SP5-6EO-LImJ"},"source":["### Part 3: KNN regression\n","\n","We can also run KNN as a regression algorithm. In this case, instead of predicting the most common class in the k nearest neighbors, we can assign a predicted value that is the mean of the values of the k neighbors.\n","\n","Make this change to your algorithm (presumably by simply implementing a new predict function below, and then calling this new predict fucntion from your knn algorithm, because you divided your code up sensibly in Part 1), and run the abalone data as a regression problem. To do this, use the same number of folds and the same k value as before. Also run a regression baseline and report RMSE values for both. Give me some explanation of the results, both standalone and in comparison to the classification results above.\n"]},{"cell_type":"code","metadata":{"id":"t4JkAnrFLImJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683507745276,"user_tz":240,"elapsed":213,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"outputId":"d6614494-452c-4e00-984d-1661b9bdca37"},"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.dummy import DummyRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","\n","def predict_regression(X_train, y_train, x_test, k):\n","    distances = []\n","    targets = []\n","    for i in range(len(X_train)):\n","        distance = np.sqrt(np.sum(np.square(x_test - X_train[i, :])))\n","        distances.append([distance, i])\n","    distances = sorted(distances)\n","    for i in range(k):\n","        index = distances[i][1]\n","        targets.append(y_train[index])\n","    return np.mean(targets)\n","\n","# Use the same data as in Part 2\n","X = abalone_ohe.drop('rings', axis=1)\n","y = abalone_ohe['rings']\n","\n","# Normalize X data\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Initialize KFold and KNN regression model\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","knn_regression = KNeighborsRegressor(n_neighbors=5)\n","\n","# Initialize lists to store accuracy and RMSE values\n","accuracy_list = []\n","rmse_list = []\n","\n","# Loop through each fold and train/test the KNN model\n","for train_idx, test_idx in kf.split(X):\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # Fit and predict with KNN regression\n","    knn_regression.fit(X_train, y_train)\n","    y_pred = knn_regression.predict(X_test)\n","\n","    # Calculate and store accuracy and RMSE values\n","    accuracy = accuracy_score(y_test, y_pred.round())\n","    accuracy_list.append(accuracy)\n","    rmse = mean_squared_error(y_test, y_pred, squared=False)\n","    rmse_list.append(rmse)\n","\n","# Print mean accuracy and RMSE values\n","print('Mean Accuracy: ', np.mean(accuracy_list))\n","print('Mean RMSE: ', np.mean(rmse_list))\n","\n","# Initialize DummyRegressor and run regression baseline\n","dummy_regr = DummyRegressor(strategy='mean')\n","dummy_regr.fit(X, y)\n","y_pred = dummy_regr.predict(X)\n","\n","# Calculate and print RMSE for regression baseline\n","rmse_baseline = mean_squared_error(y, y_pred, squared=False)\n","print('Regression Baseline RMSE: ', rmse_baseline)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Accuracy:  0.23366157636879353\n","Mean RMSE:  2.295527391695619\n","Regression Baseline RMSE:  3.2237830658212117\n"]}]},{"cell_type":"markdown","metadata":{"id":"WOzJ42AALImM"},"source":["The mean RMSE value for KNN regression is around 2.23, while the mean accuracy value for KNN classification was around 0.26. This difference is expected because regression models are better suited to continuous data, while classification models work well with categorical data.\n","\n","The regression baseline RMSE value is around 3.22, which is higher than the KNN regression RMSE value. This indicates that the KNN regression algorithm is performing better than a simple regression baseline.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T6O79qUJQMzG"},"source":["## Part 4: Introduction to scikit-learn\n","\n","One of the most popular open-source python machine learning libraries is scikit-learn. You can find out more in general at: https://scikit-learn.org/stable/index.html\n","\n","\n","As we go through this class I'll introduce you to some of the functionality. Below I want you to use BOTH a KNN Classifier and the KNN Regressor.\n","\n","I also I want you to explore the cross_val_score function. Previously you used the StratifiedKFold function. You then had to fit the model, then use the predict method to apply the model, then collect the scores, find the mean and the min and the max. cross_val_score does most of that for you.\n","\n","cross_val_score takes a model (the classifier, or regressor) you want to use, X and y data, a value for cv (the default is 5 for a 5-fold cross validation), and a scoring metric. It does all the fitting, prediction and collection of scores for you. By default, the scoring measure is accuracy, which is great for classification.\n","\n","What is returned is a list of the cross-validation scores. You can apply the .mean(), .min() and .max() methods to this list to generate scores as you have before.\n","\n","If we want to cross-validate a regression algorithm, then we need to change the scoring. Use the parameter scoring='neg_mean_squared_error'.\n","\n","To turn this neg_mean_squared_error into a meaningful score for us, we'll need to take the absolute value (to reverse the sign) and then apply math.sqrt to transform the results into RMSE.\n","\n","The links to the relevant documentation pages are:\n","- [KNN Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n","- [KNN Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)\n","- [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)\n","\n","I'll load the relevant models from scikit-learn, but it's up to you to train and test them, and report the scores appropriately, including comparison to baselines (use scikits dummy classifier) and write up. Your scores should be the broadly the same as your code, above.\n","\n","NOTE: I've added some code below to suppress the user warnings from earlier.\n"]},{"cell_type":"code","metadata":{"id":"i2DWMB2KSqHM","executionInfo":{"status":"ok","timestamp":1683506862756,"user_tz":240,"elapsed":277,"user":{"displayName":"Manav Bilakhia","userId":"01301071607022221367"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ec726bf-b272-4182-b4d3-bf3e146e555a"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.dummy import DummyClassifier\n","from sklearn.dummy import DummyRegressor\n","\n","# There are some user warnings that this time I'm going to suppress\n","import warnings\n","warnings.filterwarnings(\"ignore\",category=UserWarning)\n","\n","# Use the same data as in Parts 2 and 3\n","X = abalone_ohe.drop('rings', axis=1)\n","y = abalone_ohe['rings']\n","\n","# Normalize X data\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# KNN Classifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=5)\n","cv_classifier_scores = cross_val_score(knn_classifier, X, y, cv=5)\n","\n","print('KNN Classifier Accuracy Mean:', cv_classifier_scores.mean())\n","print('KNN Classifier Accuracy Min:', cv_classifier_scores.min())\n","print('KNN Classifier Accuracy Max:', cv_classifier_scores.max())\n","\n","# Dummy Classifier (Baseline)\n","dummy_classifier = DummyClassifier(strategy='most_frequent')\n","cv_dummy_scores = cross_val_score(dummy_classifier, X, y, cv=5)\n","\n","print('Baseline Classifier Accuracy Mean:', cv_dummy_scores.mean())\n","\n","# KNN Regressor\n","knn_regressor = KNeighborsRegressor(n_neighbors=5)\n","cv_regressor_scores = cross_val_score(knn_regressor, X, y, cv=5, scoring='neg_mean_squared_error')\n","\n","# Convert the negative mean squared error to RMSE\n","cv_regressor_scores = np.sqrt(np.abs(cv_regressor_scores))\n","\n","print('KNN Regressor RMSE Mean:', cv_regressor_scores.mean())\n","print('KNN Regressor RMSE Min:', cv_regressor_scores.min())\n","print('KNN Regressor RMSE Max:', cv_regressor_scores.max())\n","\n","# Dummy Regressor (Baseline)\n","dummy_regressor = DummyRegressor(strategy='mean')\n","cv_dummy_reg_scores = cross_val_score(dummy_regressor, X, y, cv=5, scoring='neg_mean_squared_error')\n","\n","# Convert the negative mean squared error to RMSE\n","cv_dummy_reg_scores = np.sqrt(np.abs(cv_dummy_reg_scores))\n","\n","print('Baseline Regressor RMSE Mean:', cv_dummy_reg_scores.mean())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KNN Classifier Accuracy Mean: 0.2224083889636994\n","KNN Classifier Accuracy Min: 0.19976076555023922\n","KNN Classifier Accuracy Max: 0.2452153110047847\n","Baseline Classifier Accuracy Mean: 0.16495086382259405\n","KNN Regressor RMSE Mean: 2.3022349564287032\n","KNN Regressor RMSE Min: 1.642148202113119\n","KNN Regressor RMSE Max: 3.4192531152327272\n","Baseline Regressor RMSE Mean: 3.2226946578821867\n"]}]},{"cell_type":"markdown","metadata":{"id":"2VTMG4PrFKMg"},"source":["The KNN Classifier achieved an average accuracy score of 0.22, with a minimum score of 0.20 and a maximum score of 0.25. These findings demonstrate the KNN Classifier's performance in accurately classifying the target variable based on the input features.\n","\n","In contrast, the Dummy Classifier attained an average accuracy score of 0.16. Comparing this score to the KNN Classifier's accuracy, it is evident that the KNN Classifier surpassed the baseline, indicating that it offers more meaningful predictions than a simplistic strategy of assigning the most frequent class.\n","\n","Regarding the KNN Regressor, its mean root mean squared error (RMSE) was 2.30. The KNN Regressor achieved a minimum RMSE of 1.64 and a maximum RMSE of 3.42. These outcomes emphasize the KNN Regressor's ability to reasonably estimate the target variable.\n","\n","On the other hand, the Dummy Regressor predicts the mean value of the training data for all instances. The mean RMSE score of the Dummy Regressor was 3.22. By comparing this score to the KNN Regressor's RMSE, it becomes apparent that the KNN Regressor outperformed the baseline, indicating that it provides more accurate predictions than a naive approach of predicting the mean value.\n"]}]}